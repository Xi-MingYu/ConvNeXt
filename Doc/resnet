#Resnet论文精读
##基本介绍
###发现问题
1.网络足够深时，网络的前向传播会出现梯度爆炸和梯度消失，
常规解决方法是权重初始化时不要特别大也不要特别小或者加入BN层归一化
2.网络足够深时也会出现性能下降，
但并不是因为模型变复杂过拟合所导致的，因为在论文中测试误差和训练误差都增大，
网络虽然收敛但是并没有取得一个好的结果
3.论文中经过一个讨论，如果有一个浅层神经网络训练效果不错，
在此基础上更深的网络不应该是变差的，新加入的层总归可以看成是“identity mapping”，
理应获得和浅层模型相近的结果，但现实却不是这样的，新加的层往往是在“帮倒忙”。
###解决思路
![img.png](img.png)
加入如图的残差结构。不细致了解的话到此为止了。
